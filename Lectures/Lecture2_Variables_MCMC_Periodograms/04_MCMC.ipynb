{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "<style>\n",
       "\n",
       "@import url(https://fonts.googleapis.com/css?family=Open+Sans);body{\n",
       "   font-family: 'Open Sans';\n",
       "   font-size: 125%;\n",
       "}\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 275%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.3; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC for Bayesian Inference\n",
    "\n",
    "<font color=\"grey\">AY128/256 (UC Berkeley 2018$-$2021)</font>\n",
    "\n",
    "As we just saw in the Bayes intro, there are some cases where we can get a closed/analytic form of the posterior, but many examples we cannot get a closed form. Instead we need to sample the posterior numerically.\n",
    "\n",
    "- Markov Chain Monte Carlo: Stochastic methods useful for sampling from the target posterior distribution\n",
    "\n",
    "- Can be implmented where conjugacy does not hold and grid appoximations fail\n",
    "\n",
    "- Can work in high dimensions\n",
    "\n",
    "- Iterative: we must decide when convergance has happened\n",
    "\n",
    "- Some Popular methods: [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm), [NUTS (No U-Turns)](https://arxiv.org/abs/1111.4246), [Hessian-Hamiltonian](https://people.csail.mit.edu/tzumao/h2mc/)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Idea</u>: Suppose that sampling from the posterior $p(\\theta|$**X**) is hard but that we can somehow generate a [Markov chain](http://setosa.io/ev/markov-chains/) $\\{\\theta(t), t \\in T\\}$ with stationary distribution $p(\\theta|$**X**)\n",
    "\n",
    "- We want to set up a chain that will take us to the stationary distribution $\\pi = p(\\theta|$**X**)\n",
    "\n",
    "- Once we find such a chain, we will start from some initial guess $\\theta^0$ and tun the chain for a large number of steps until it converged to $\\pi$\n",
    "\n",
    "- After convergence we run a bunch more steps of the chain and use those as draws from $p(\\theta|$**X**).\n",
    "\n",
    "- All MCMC methods are based on this idea. The differences are in how the Markov chain transitions are created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/ma.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/ma1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize different approaches to sampling [here](https://chi-feng.github.io/mcmc-demo/app.html#AdaptiveMH,standard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC with PyMC\n",
    "https://pymc-devs.github.io/pymc3/\n",
    "\n",
    "<img width=\"20%\" src=\"https://docs.pymc.io/_static/pymc3_logo.jpg\">\n",
    "\n",
    "https://docs.pymc.io/examples.html\n",
    "\n",
    "```\n",
    "\n",
    "conda install pymc3 arviz\n",
    "# pip install pymc3 arviz\n",
    "```\n",
    "\n",
    "PyMC3 is the most widely used Markov chain Monte Carlo module in Python\n",
    "\n",
    "- It allows straightforward coding of probability models and posterior sampling of those models with standard (optimized) MCMC algorithms\n",
    "- Large and complicated (hierarchical) models can be easily coded in PyMC\n",
    "- Convergence diagnostics and automatic tuning are provided \n",
    "- Users can input custom probability distributions and fitting algorithms \n",
    "- Great documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the Presidental approval rating again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymc3 arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "a = 700\n",
    "n = 1429\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "\n",
    "x_theta = np.linspace(0, 1, 101)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "p_theta = stats.beta(alpha + a, beta + n - a).pdf(x_theta)\n",
    "ax.plot(x_theta, p_theta, linewidth=3.,label=f\"{alpha}, {beta}\")\n",
    "    \n",
    "ax.legend()\n",
    "ax.set_ylim([0, max(p_theta)])\n",
    "ax.set_xlabel(r\"$\\theta$\")\n",
    "ax.set_ylabel(r\"$p(\\theta)$\")\n",
    "ax.set_title(\"Posterior distribution: Biden Approval Feb 2-3, 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "from arviz import plot_trace as traceplot\n",
    "\n",
    "with pm.Model() as model:\n",
    "    theta = pm.Beta('theta', alpha, beta)\n",
    "    X = pm.Binomial('X', n, theta, observed=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.Binomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS()\n",
    "    trace = pm.sample(20000, step=step, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    traceplot(trace[1000:][::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we started sampling after a burn-in period of a thousand steps. We also \"pruned\" the result by taking only every 5th step (helps insure some level of independence between samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "xx = plt.hist(trace['theta'][1000:][::5], bins=50, label='MCMC posterior', density=True)\n",
    "plt.vlines(x=a / n, ymin=0, ymax=max(xx[0])+1, linestyle='--', label=\"Max likelihood\")\n",
    "plt.plot(x_theta, p_theta, linewidth=3.,label=f\"{alpha}, {beta}\")\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"$p(\\theta)$\")\n",
    "plt.legend()\n",
    "plt.xlim(0.3,0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our MCMC results agree with the (closed-form) solution for this simple case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have samples from the posterior we can do cool things:\n",
    "\n",
    "Suppose we have B samples $\\theta_1$...$\\theta_B$ from the posterior $p(\\theta|$**X**):\n",
    "\n",
    "1) **Posterior mean**: \n",
    "   \n",
    "The exact equation $E[\\theta|$**X**] = $\\int \\theta p(\\theta|$**X**)$d\\theta$\n",
    "\n",
    "Using the sample $E[\\theta|$**X**] $\\approx \\frac{1}{B} \\sum_{b=1}^B \\theta_b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace['theta'][1000:][::5].sum()/len(trace['theta'][1000:][::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) **Marginalization**: \n",
    "   \n",
    "The exact equation $p(\\theta_1|$**X**) = $\\int p(\\theta_1,\\theta_2,..\\theta_p|$**X**)$d\\theta_2\\theta_3...\\theta_p$\n",
    "\n",
    "Using the sample $p(\\theta_1|$**X**) $\\sim \\theta_{1,1} ... \\theta_{1,B}$\n",
    "\n",
    "*That is, record the parameter of interest $\\theta_1$ from each sample.*\n",
    "\n",
    "3) **Prediction**: \n",
    "   \n",
    "The exact equation $p(\\tilde{X}|$**X**) = $\\int p(\\tilde{X}|\\theta) p(\\theta|$**X**)$d\\theta$\n",
    "\n",
    "Using the sample $p(\\tilde{X}|$**X**) $\\sim \\tilde{x_1} | \\theta_{1} ... \\tilde{x_B} | \\theta_{B}$\n",
    "\n",
    "*That is, take each sample of $\\theta$ and determine a value for $x$.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
